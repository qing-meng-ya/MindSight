# AutoDLäº‘æœåŠ¡å™¨è®­ç»ƒæŒ‡å—

æœ¬æŒ‡å—ä¸“é—¨é’ˆå¯¹åœ¨AutoDLäº‘æœåŠ¡å™¨ä¸Šè®­ç»ƒç»„ç»‡ç—…ç†CNNæ¨¡å‹æä¾›è¯¦ç»†çš„æ“ä½œæ­¥éª¤å’Œä¼˜åŒ–å»ºè®®ã€‚

## ğŸ¯ ä¸ºä»€ä¹ˆé€‰æ‹©AutoDLï¼Ÿ

- **GPUèµ„æºä¸°å¯Œ**ï¼šæä¾›RTX 3090/4090ã€A100ç­‰é«˜æ€§èƒ½GPU
- **ç¯å¢ƒé¢„é…ç½®**ï¼šPyTorchã€CUDAç­‰æ·±åº¦å­¦ä¹ ç¯å¢ƒå·²é¢„è£…
- **æŒ‰éœ€ä»˜è´¹**ï¼šæŒ‰å°æ—¶è®¡è´¹ï¼Œé¿å…ç¡¬ä»¶é—²ç½®æˆæœ¬
- **å­˜å‚¨çµæ´»**ï¼šä¸´æ—¶å­˜å‚¨+æŒä¹…åŒ–å­˜å‚¨æ–¹æ¡ˆ
- **ä¸€é”®éƒ¨ç½²**ï¼šæ”¯æŒJupyterã€SSHç­‰å¤šç§è®¿é—®æ–¹å¼

## ğŸš€ AutoDLè®­ç»ƒæµç¨‹

### 1. é€‰æ‹©åˆé€‚çš„GPUå®ä¾‹

| GPUå‹å· | æ˜¾å­˜ | é€‚ç”¨åœºæ™¯ | æ¨èé…ç½® |
|---------|------|----------|----------|
| RTX 4090 | 24GB | å¤§è§„æ¨¡è®­ç»ƒ | batch_size=32, img_size=384 |
| RTX 3090 | 24GB | å¹³è¡¡æ€§èƒ½ | batch_size=32, img_size=320 |
| A100 | 40GB | æœ€å¤§è§„æ¨¡ | batch_size=64, img_size=512 |
| RTX 3080 | 10GB | æ ‡å‡†è®­ç»ƒ | batch_size=16, img_size=256 |
| RTX 3060 | 12GB | ç»æµå‹ | batch_size=16, img_size=224 |

**æ¨èé€‰æ‹©**ï¼šRTX 4090 (æ€§ä»·æ¯”æœ€é«˜)

### 2. åˆ›å»ºAutoDLå®ä¾‹

#### 2.1 è®¿é—®AutoDLæ§åˆ¶å°
1. ç™»å½• [AutoDLå®˜ç½‘](https://www.autodl.com/)
2. è¿›å…¥"ç®—åŠ›å¸‚åœº"
3. é€‰æ‹©åˆé€‚çš„GPUå®ä¾‹

#### 2.2 é…ç½®å®ä¾‹å‚æ•°
```bash
# æ¨èé…ç½®
é•œåƒ: PyTorch 2.0 + CUDA 11.8
ç³»ç»Ÿ: Ubuntu 20.04
å­˜å‚¨: 100GB+
GPU: RTX 4090 x 1
```

### 3. ä¸Šä¼ é¡¹ç›®æ–‡ä»¶

#### 3.1 æ–¹å¼ä¸€ï¼šGitå…‹éš†ï¼ˆæ¨èï¼‰
```bash
# åœ¨AutoDLå®ä¾‹ä¸­æ‰§è¡Œ
git clone <your-repository-url>
cd ç»„ç»‡ç—…ç†CNN
```

#### 3.2 æ–¹å¼äºŒï¼šæ–‡ä»¶ä¸Šä¼ 
```bash
# ä¸Šä¼ å‹ç¼©åŒ…
scp -r pathology_cnn.zip user@autodl-instance:/root/
# è§£å‹
unzip pathology_cnn.zip
cd ç»„ç»‡ç—…ç†CNN
```

#### 3.3 æ–¹å¼ä¸‰ï¼šä½¿ç”¨AutoDLæ–‡ä»¶ç®¡ç†å™¨
1. ç™»å½•AutoDLæ§åˆ¶å°
2. é€‰æ‹©å®ä¾‹ â†’ æ–‡ä»¶ç®¡ç†
3. ä¸Šä¼ é¡¹ç›®æ–‡ä»¶

### 4. å‡†å¤‡è®­ç»ƒæ•°æ®

#### 4.1 æ•°æ®ç›®å½•ç»“æ„
```
/root/autodl-tmp/datasets/pathology_raw/
â”œâ”€â”€ è‚ºç‚/
â”‚   â”œâ”€â”€ img001.jpg
â”‚   â”œâ”€â”€ img002.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ è‚ºå‡ºè¡€/
â”œâ”€â”€ è‚ºæ°´è‚¿/
â”œâ”€â”€ è‚ºè¡€æ “/
â”œâ”€â”€ å† å¿ƒç—…/
â”œâ”€â”€ è„‘å‡ºè¡€/
â”œâ”€â”€ è‚è„‚è‚ªå˜æ€§/
â””â”€â”€ ... (å…¶ä»–ç—…ç†ç±»å‹)
```

#### 4.2 æ•°æ®ä¸Šä¼ æ–¹å¼

**æ–¹å¼ä¸€ï¼šAutoDLæ•°æ®é›†**
1. åœ¨æ§åˆ¶å°é€‰æ‹©"æ•°æ®é›†"
2. ä¸Šä¼ æ•°æ®é›†ï¼ˆæ”¯æŒå‹ç¼©åŒ…ï¼‰
3. æŒ‚è½½åˆ°å®ä¾‹

**æ–¹å¼äºŒï¼šç›´æ¥ä¸Šä¼ **
```bash
# ä½¿ç”¨scpä¸Šä¼ 
scp -r local_data/ user@autodl-instance:/root/autodl-tmp/datasets/pathology_raw

# æˆ–ä½¿ç”¨rsyncï¼ˆå¤§æ–‡ä»¶æ¨èï¼‰
rsync -av --progress local_data/ user@autodl-instance:/root/autodl-tmp/datasets/pathology_raw
```

#### 4.3 æ•°æ®éªŒè¯
```bash
# éªŒè¯æ•°æ®ç»“æ„
python3 -c "
import os
data_dir = '/root/autodl-tmp/datasets/pathology_raw'
for class_name in os.listdir(data_dir):
    class_dir = os.path.join(data_dir, class_name)
    if os.path.isdir(class_dir):
        images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.png', '.tiff'))]
        print(f'{class_name}: {len(images)} å¼ å›¾åƒ')
"
```

### 5. å®‰è£…ä¾èµ–å’Œé…ç½®ç¯å¢ƒ

#### 5.1 è‡ªåŠ¨é…ç½®ï¼ˆæ¨èï¼‰
```bash
# ä½¿ç”¨æä¾›çš„é…ç½®è„šæœ¬
chmod +x autodl/setup_autodl.sh
./autodl/setup_autodl.sh
```

#### 5.2 æ‰‹åŠ¨é…ç½®
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv /root/pathology_env
source /root/pathology_env/bin/activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# éªŒè¯å®‰è£…
python3 -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}')"
```

### 6. å¼€å§‹è®­ç»ƒ

#### 6.1 ä¸€é”®å¯åŠ¨è®­ç»ƒ
```bash
# ä½¿ç”¨ä¼˜åŒ–çš„è®­ç»ƒè„šæœ¬
chmod +x autodl/train_autodl.sh
./autodl/train_autodl.sh
```

#### 6.2 æ‰‹åŠ¨è®­ç»ƒï¼ˆè‡ªå®šä¹‰å‚æ•°ï¼‰
```bash
# åŸºç¡€è®­ç»ƒ
python scripts/train_autodl.py \
  --data_dir /root/autodl-tmp/datasets/pathology_raw \
  --epochs 100

# é«˜çº§é…ç½®
python scripts/train_autodl.py \
  --data_dir /root/autodl-tmp/datasets/pathology_raw \
  --model_type efficientnet_b1 \
  --batch_size 32 \
  --img_size 384 \
  --epochs 100 \
  --lr 0.001 \
  --loss_type combined \
  --mixed_precision \
  --experiment_name "exp_v1_large"
```

#### 6.3 ç›‘æ§è®­ç»ƒè¿›åº¦
```bash
# æŸ¥çœ‹æ—¥å¿—
tail -f /root/autodl-fs/experiment_name/logs/training_*.log

# ç›‘æ§GPUä½¿ç”¨
watch -n 2 nvidia-smi

# æŸ¥çœ‹è®­ç»ƒç»Ÿè®¡
python3 -c "
import json
with open('/root/autodl-fs/experiment_name/training_stats.json') as f:
    stats = json.load(f)
print(f'è®­ç»ƒæ—¶é—´: {stats[\"total_time\"]/3600:.2f} å°æ—¶')
print(f'æœ€ä½³F1: {max(stats[\"epoch_times\"])}')
"
```

### 7. æ¨¡å‹ç®¡ç†å’Œå¤‡ä»½

#### 7.1 è‡ªåŠ¨å¤‡ä»½
è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ï¼š
- æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡æ¨¡å‹
- éªŒè¯é›†æ€§èƒ½æå‡æ—¶ä¿å­˜æœ€ä½³æ¨¡å‹
- è®­ç»ƒå®Œæˆåå¤‡ä»½åˆ°æŒä¹…åŒ–å­˜å‚¨

#### 7.2 æ‰‹åŠ¨å¤‡ä»½
```bash
# å¤‡ä»½åˆ°æœ¬åœ°
scp -r user@autodl-instance:/root/autodl-fs/experiment_name ./

# ä¸‹è½½æœ€ä½³æ¨¡å‹
scp user@autodl-instance:/root/autodl-fs/experiment_name/models/best_model.pth ./
```

#### 7.3 æ¨¡å‹è¯„ä¼°
```bash
# åœ¨AutoDLä¸Šè¯„ä¼°
python scripts/evaluate.py \
  --data_dir /root/autodl-tmp/datasets/pathology_raw \
  --model_path /root/autodl-fs/experiment_name/models/best_model.pth \
  --output_dir /root/autodl-fs/evaluation_results
```

## ğŸ”§ AutoDLä¼˜åŒ–æŠ€å·§

### 1. GPUå†…å­˜ä¼˜åŒ–

#### 1.1 è‡ªåŠ¨é…ç½®
ç³»ç»Ÿä¼šæ ¹æ®GPUå†…å­˜è‡ªåŠ¨è°ƒæ•´ï¼š
- RTX 4090 (24GB): batch_size=32, img_size=384
- RTX 3090 (24GB): batch_size=32, img_size=320
- RTX 3080 (10GB): batch_size=16, img_size=256

#### 1.2 æ‰‹åŠ¨ä¼˜åŒ–
```bash
# å‡å°batch size
python scripts/train_autodl.py \
  --batch_size 16 \
  --img_size 256

# å¯ç”¨æ¢¯åº¦ç´¯ç§¯
# åœ¨autodl_config.pyä¸­è°ƒæ•´accumulation_steps

# å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
python scripts/train_autodl.py --mixed_precision
```

### 2. å­˜å‚¨ä¼˜åŒ–

#### 2.1 å­˜å‚¨ç­–ç•¥
- **ä¸´æ—¶å­˜å‚¨** (`/root/autodl-tmp/`): é«˜é€ŸSSDï¼Œç”¨äºè®­ç»ƒæ•°æ®
- **æŒä¹…åŒ–å­˜å‚¨** (`/root/autodl-fs/`): ç½‘ç»œå­˜å‚¨ï¼Œç”¨äºæ¨¡å‹å¤‡ä»½

#### 2.2 æ•°æ®ç¼“å­˜
```bash
# è§£å‹æ•°æ®åˆ°ä¸´æ—¶å­˜å‚¨
unzip dataset.zip -d /root/autodl-tmp/datasets/

# é¢„å¤„ç†æ•°æ®ç¼“å­˜
python -c "
import os
from pathlib import Path
# åˆ›å»ºé¢„å¤„ç†ç¼“å­˜ç›®å½•
cache_dir = Path('/root/autodl-tmp/cache')
cache_dir.mkdir(exist_ok=True)
"
```

### 3. è®­ç»ƒä¼˜åŒ–

#### 3.1 æ··åˆç²¾åº¦è®­ç»ƒ
```python
# è‡ªåŠ¨å¯ç”¨æ··åˆç²¾åº¦ï¼ˆé»˜è®¤å¼€å¯ï¼‰
# åœ¨RTX 20ç³»åˆ—åŠæ›´æ–°GPUä¸Šå¯æ˜¾è‘—åŠ é€Ÿ
```

#### 3.2 æ•°æ®åŠ è½½ä¼˜åŒ–
```python
# å¢åŠ workeræ•°é‡
# åœ¨autodl_config.pyä¸­è°ƒæ•´num_workers = min(8, cpu_count())

# å¯ç”¨pin_memory
# è‡ªåŠ¨è®¾ç½®ä¸ºTrue
```

#### 3.3 å­¦ä¹ ç‡è°ƒåº¦
```python
# è‡ªåŠ¨ä½¿ç”¨ReduceLROnPlateau
# æ ¹æ®éªŒè¯é›†F1è°ƒæ•´å­¦ä¹ ç‡
```

## ğŸ“Š ç›‘æ§å’Œè°ƒè¯•

### 1. å®æ—¶ç›‘æ§

#### 1.1 ç³»ç»Ÿç›‘æ§
```bash
# GPUç›‘æ§
watch -n 1 nvidia-smi

# å†…å­˜ç›‘æ§
watch -n 5 free -h

# ç£ç›˜ç›‘æ§
watch -n 10 df -h
```

#### 1.2 è®­ç»ƒç›‘æ§
```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f /root/autodl-fs/*/logs/training_*.log

# æŸ¥çœ‹æ¨¡å‹ä¿å­˜æƒ…å†µ
ls -la /root/autodl-fs/*/models/
```

### 2. å¸¸è§é—®é¢˜æ’æŸ¥

#### 2.1 å†…å­˜ä¸è¶³
```bash
# æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨
python3 -c "
import torch
print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1024**3:.1f}GB')
print(f'Allocated: {torch.cuda.memory_allocated()/1024**3:.1f}GB')
print(f'Cached: {torch.cuda.memory_reserved()/1024**3:.1f}GB')
"

# æ¸…ç†ç¼“å­˜
torch.cuda.empty_cache()
```

#### 2.2 è®­ç»ƒé€Ÿåº¦æ…¢
```bash
# æ£€æŸ¥æ•°æ®åŠ è½½ç“¶é¢ˆ
# åœ¨ä»£ç ä¸­æ·»åŠ æ—¶é—´ç»Ÿè®¡
import time
start = time.time()
# æ•°æ®åŠ è½½ä»£ç 
print(f'Load time: {time.time()-start:.2f}s')
```

#### 2.3 æ¨¡å‹ä¸æ”¶æ•›
- æ£€æŸ¥å­¦ä¹ ç‡è®¾ç½®
- éªŒè¯æ•°æ®è´¨é‡
- å°è¯•ä¸åŒçš„æŸå¤±å‡½æ•°
- å¢åŠ æ•°æ®å¢å¼º

### 3. æ€§èƒ½è°ƒä¼˜

#### 3.1 æ‰¹æ¬¡å¤§å°è°ƒä¼˜
```bash
# ä»å°batchå¼€å§‹æµ‹è¯•
for bs in 8 16 32 64; do
    python scripts/train_autodl.py --batch_size $bs --epochs 5
    # è®°å½•GPUä½¿ç”¨ç‡å’Œè®­ç»ƒé€Ÿåº¦
done
```

#### 3.2 å›¾åƒå°ºå¯¸è°ƒä¼˜
```bash
# æµ‹è¯•ä¸åŒå›¾åƒå°ºå¯¸
for size in 224 256 320 384 512; do
    python scripts/train_autodl.py --img_size $size --epochs 5
    # è®°å½•å‡†ç¡®ç‡å’Œé€Ÿåº¦
done
```

## ğŸ’° æˆæœ¬ä¼˜åŒ–å»ºè®®

### 1. é€‰æ‹©åˆé€‚çš„å®ä¾‹
- **çŸ­æœŸè®­ç»ƒ**ï¼šRTX 4090 (å•ä»·é«˜ä½†ç”¨æ—¶çŸ­)
- **é•¿æœŸè®­ç»ƒ**ï¼šRTX 3090 (æ€§ä»·æ¯”é«˜)
- **å®éªŒæµ‹è¯•**ï¼šRTX 3060 (ç»æµå®æƒ )

### 2. æ—¶é—´ç®¡ç†
- **é¢„ä¼°è®­ç»ƒæ—¶é—´**ï¼šæ ¹æ®æ•°æ®é‡å’ŒGPUæ€§èƒ½
- **è®¾ç½®åˆç†çš„æ—©åœ**ï¼šé¿å…æ— æ•ˆè®­ç»ƒ
- **ä½¿ç”¨æ£€æŸ¥ç‚¹**ï¼šæ”¯æŒæ–­ç‚¹ç»­è®­

### 3. å­˜å‚¨ä¼˜åŒ–
- **æ•°æ®å‹ç¼©**ï¼šä½¿ç”¨å‹ç¼©æ ¼å¼ä¸Šä¼ æ•°æ®
- **åŠæ—¶æ¸…ç†**ï¼šè®­ç»ƒç»“æŸåæ¸…ç†ä¸´æ—¶æ–‡ä»¶
- **å¢é‡å¤‡ä»½**ï¼šåªå¤‡ä»½é‡è¦çš„æ¨¡å‹æ–‡ä»¶

## ğŸš€ é«˜çº§åŠŸèƒ½

### 1. åˆ†å¸ƒå¼è®­ç»ƒ
```bash
# å¤šGPUè®­ç»ƒï¼ˆå¦‚æœæœ‰å¤šä¸ªGPUï¼‰
python -m torch.distributed.launch \
  --nproc_per_node=2 \
  scripts/train_autodl.py \
  --data_dir /root/autodl-tmp/datasets/pathology_raw
```

### 2. è‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜
```bash
# ä½¿ç”¨ç½‘æ ¼æœç´¢
for lr in 0.001 0.0005 0.0001; do
  for bs in 16 32 64; do
    python scripts/train_autodl.py \
      --lr $lr --batch_size $bs \
      --experiment_name "tune_lr${lr}_bs${bs}"
  done
done
```

### 3. æ¨¡å‹é›†æˆ
```bash
# è®­ç»ƒå¤šä¸ªæ¨¡å‹è¿›è¡Œé›†æˆ
for model_type in resnet50 efficientnet_b1 efficientnet_b2; do
  python scripts/train_autodl.py \
    --model_type $model_type \
    --experiment_name "ensemble_${model_type}"
done
```

## ğŸ“ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

1. **GPUå†…å­˜ä¸è¶³**
   - å‡å°batch_size
   - å‡å°img_size  
   - å¯ç”¨æ¢¯åº¦ç´¯ç§¯

2. **è®­ç»ƒé€Ÿåº¦æ…¢**
   - å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
   - å¢åŠ æ•°æ®åŠ è½½workeræ•°é‡
   - æ£€æŸ¥æ•°æ®I/Oç“¶é¢ˆ

3. **æ¨¡å‹ä¸æ”¶æ•›**
   - è°ƒæ•´å­¦ä¹ ç‡
   - æ£€æŸ¥æ•°æ®è´¨é‡
   - å°è¯•ä¸åŒæŸå¤±å‡½æ•°

4. **è¿æ¥ä¸­æ–­**
   - ä½¿ç”¨æ–­ç‚¹ç»­è®­
   - å®šæœŸå¤‡ä»½åˆ°æŒä¹…åŒ–å­˜å‚¨
   - ä½¿ç”¨tmux/screenä¿æŒä¼šè¯

5. **æ•°æ®ä¸Šä¼ å¤±è´¥**
   - ä½¿ç”¨å‹ç¼©åŒ…ä¸Šä¼ 
   - åˆ†æ‰¹ä¸Šä¼ å¤§æ–‡ä»¶
   - ä½¿ç”¨rsyncæ›¿ä»£scp

## ğŸ¯ æ€»ç»“

AutoDLå¹³å°ä¸ºç»„ç»‡ç—…ç†CNNè®­ç»ƒæä¾›äº†å¼ºå¤§çš„è®¡ç®—èµ„æºå’Œçµæ´»çš„é…ç½®é€‰é¡¹ã€‚é€šè¿‡æœ¬æŒ‡å—çš„ä¼˜åŒ–é…ç½®å’Œæœ€ä½³å®è·µï¼Œæ‚¨å¯ä»¥ï¼š

- âœ… å……åˆ†åˆ©ç”¨GPUèµ„æºï¼Œæœ€å¤§åŒ–è®­ç»ƒæ•ˆç‡
- âœ… åˆç†æ§åˆ¶æˆæœ¬ï¼Œé¿å…èµ„æºæµªè´¹
- âœ… ç¡®ä¿è®­ç»ƒç¨³å®šæ€§å’Œç»“æœå¯é æ€§
- âœ… å®ç°é«˜æ•ˆçš„æ¨¡å‹å¼€å‘å’Œè¿­ä»£

å¼€å§‹æ‚¨çš„AutoDLè®­ç»ƒä¹‹æ—…å§ï¼ğŸš€