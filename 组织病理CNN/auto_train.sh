#!/bin/bash

# ç»„ç»‡ç—…ç†CNNå…¨è‡ªåŠ¨è®­ç»ƒè„šæœ¬
# åªéœ€è¦å‡†å¤‡æ•°æ®ï¼Œå…¶ä»–å…¨éƒ¨è‡ªåŠ¨åŒ–

set -e

echo "ğŸš€ ç»„ç»‡ç—…ç†CNNå…¨è‡ªåŠ¨è®­ç»ƒ"
echo "=================================="

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}â„¹ï¸  $1${NC}"
}

log_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

log_warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}"
}

log_error() {
    echo -e "${RED}âŒ $1${NC}"
}

# æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ
check_environment() {
    log_info "æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ..."
    
    # æ£€æŸ¥Python
    if ! command -v python3 &> /dev/null; then
        log_error "Python3æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Python 3.8+"
        exit 1
    fi
    log_success "Python: $(python3 --version)"
    
    # æ£€æŸ¥GPU
    if command -v nvidia-smi &> /dev/null; then
        GPU_INFO=$(nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits | head -1)
        log_success "GPU: $GPU_INFO"
        export CUDA_VISIBLE_DEVICES=0
        USE_GPU=true
    else
        log_warning "æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ"
        USE_GPU=false
    fi
    
    # æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
    if [[ "$VIRTUAL_ENV" != "" ]]; then
        log_success "è™šæ‹Ÿç¯å¢ƒ: $VIRTUAL_ENV"
    else
        log_warning "æœªæ£€æµ‹åˆ°è™šæ‹Ÿç¯å¢ƒï¼Œå»ºè®®ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ"
    fi
}

# è‡ªåŠ¨å®‰è£…ä¾èµ–
install_dependencies() {
    log_info "æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–åŒ…..."
    
    # å‡çº§pip
    python3 -m pip install --upgrade pip
    
    # å®‰è£…ä¾èµ–
    if python3 -m pip install -r requirements.txt; then
        log_success "ä¾èµ–åŒ…å®‰è£…å®Œæˆ"
    else
        log_error "ä¾èµ–åŒ…å®‰è£…å¤±è´¥"
        exit 1
    fi
    
    # éªŒè¯å…³é”®åŒ…
    python3 -c "
import torch, cv2, fastapi
print(f'âœ… PyTorch: {torch.__version__}')
print(f'âœ… OpenCV: {cv2.__version__}')
print(f'âœ… FastAPI: {fastapi.__version__}')
print(f'âœ… CUDAå¯ç”¨: {torch.cuda.is_available()}')
"
}

# å‡†å¤‡æ•°æ®ç›®å½•
prepare_directories() {
    log_info "å‡†å¤‡ç›®å½•ç»“æ„..."
    
    # åˆ›å»ºå¿…è¦ç›®å½•
    mkdir -p data/raw data/processed data/models
    mkdir -p evaluation_results logs
    log_success "ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ"
}

# æ£€æŸ¥è®­ç»ƒæ•°æ®
check_training_data() {
    log_info "æ£€æŸ¥è®­ç»ƒæ•°æ®..."
    
    if [[ ! -d "data/raw" ]]; then
        log_error "æ•°æ®ç›®å½•ä¸å­˜åœ¨: data/raw"
        echo "è¯·æŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡æ•°æ®:"
        echo "data/raw/"
        echo "â”œâ”€â”€ è‚ºç‚/"
        echo "â”‚   â”œâ”€â”€ image001.jpg"
        echo "â”‚   â””â”€â”€ image002.jpg"
        echo "â”œâ”€â”€ è‚ºå‡ºè¡€/"
        echo "â””â”€â”€ ..."
        exit 1
    fi
    
    # ç»Ÿè®¡æ•°æ®
    TOTAL_IMAGES=0
    CLASS_COUNT=0
    for class_dir in data/raw/*/; do
        if [[ -d "$class_dir" ]]; then
            CLASS_NAME=$(basename "$class_dir")
            IMAGE_COUNT=$(find "$class_dir" -type f \( -name "*.jpg" -o -name "*.png" -o -name "*.tiff" \) | wc -l)
            if [[ $IMAGE_COUNT -gt 0 ]]; then
                echo "   $CLASS_NAME: $IMAGE_COUNT å¼ å›¾åƒ"
                TOTAL_IMAGES=$((TOTAL_IMAGES + IMAGE_COUNT))
                CLASS_COUNT=$((CLASS_COUNT + 1))
            fi
        fi
    done
    
    if [[ $TOTAL_IMAGES -eq 0 ]]; then
        log_error "æœªæ‰¾åˆ°æœ‰æ•ˆçš„å›¾åƒæ–‡ä»¶"
        exit 1
    fi
    
    log_success "æ•°æ®æ£€æŸ¥å®Œæˆ: $CLASS_COUNT ä¸ªç±»åˆ«, $TOTAL_IMAGES å¼ å›¾åƒ"
    
    # æ£€æŸ¥æ•°æ®å……è¶³æ€§
    if [[ $TOTAL_IMAGES -lt 100 ]]; then
        log_warning "æ•°æ®é‡è¾ƒå°‘ (<100å¼ )ï¼Œå¯èƒ½å½±å“è®­ç»ƒæ•ˆæœ"
    elif [[ $TOTAL_IMAGES -lt 500 ]]; then
        log_warning "æ•°æ®é‡é€‚ä¸­ (100-500å¼ )ï¼Œå»ºè®®å¢åŠ æ•°æ®"
    else
        log_success "æ•°æ®é‡å……è¶³ (>500å¼ )"
    fi
}

# è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜é…ç½®
select_optimal_config() {
    log_info "è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è®­ç»ƒé…ç½®..."
    
    if [[ "$USE_GPU" == "true" ]]; then
        # è·å–GPUå†…å­˜
        GPU_MEMORY=$(python3 -c "
import torch
if torch.cuda.is_available():
    memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
    print(f'{memory_gb:.0f}')
else:
    print('0')
" 2>/dev/null || echo "0")
        
        log_info "GPUå†…å­˜: ${GPU_MEMORY}GB"
        
        # æ ¹æ®GPUå†…å­˜é€‰æ‹©é…ç½®
        if [[ $GPU_MEMORY -ge 24 ]]; then
            # RTX 4090/3090/A100
            MODEL_TYPE="efficientnet_b1"
            BATCH_SIZE=32
            IMG_SIZE=384
            EPOCHS=100
        elif [[ $GPU_MEMORY -ge 16 ]]; then
            # RTX 3080/4080
            MODEL_TYPE="resnet50"
            BATCH_SIZE=24
            IMG_SIZE=320
            EPOCHS=80
        elif [[ $GPU_MEMORY -ge 12 ]]; then
            # RTX 3060/3070
            MODEL_TYPE="resnet50"
            BATCH_SIZE=16
            IMG_SIZE=256
            EPOCHS=60
        else
            # å°GPUæˆ–CPU
            MODEL_TYPE="resnet34"
            BATCH_SIZE=8
            IMG_SIZE=224
            EPOCHS=40
        fi
    else
        # CPUè®­ç»ƒ
        MODEL_TYPE="resnet34"
        BATCH_SIZE=4
        IMG_SIZE=224
        EPOCHS=20
    fi
    
    log_success "è®­ç»ƒé…ç½®:"
    echo "   æ¨¡å‹ç±»å‹: $MODEL_TYPE"
    echo "   æ‰¹æ¬¡å¤§å°: $BATCH_SIZE"
    echo "   å›¾åƒå°ºå¯¸: $IMG_SIZE"
    echo "   è®­ç»ƒè½®æ¬¡: $EPOCHS"
    
    # ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
    cat > training_config.json << EOF
{
    "model_type": "$MODEL_TYPE",
    "batch_size": $BATCH_SIZE,
    "img_size": $IMG_SIZE,
    "epochs": $EPOCHS",
    "use_gpu": $USE_GPU,
    "auto_config": true,
    "timestamp": "$(date -Iseconds)"
}
EOF
    
    log_success "é…ç½®å·²ä¿å­˜: training_config.json"
}

# å¼€å§‹è®­ç»ƒ
start_training() {
    log_info "å¼€å§‹è‡ªåŠ¨è®­ç»ƒ..."
    
    # æ„å»ºè®­ç»ƒå‘½ä»¤
    TRAIN_CMD="python scripts/train.py \
        --data_dir data/raw \
        --model_type $MODEL_TYPE \
        --batch_size $BATCH_SIZE \
        --img_size $IMG_SIZE \
        --epochs $EPOCHS \
        --loss_type focal \
        --use_class_weights"
    
    if [[ "$USE_GPU" == "true" ]]; then
        TRAIN_CMD="$TRAIN_CMD --device cuda"
    else
        TRAIN_CMD="$TRAIN_CMD --device cpu"
    fi
    
    log_info "æ‰§è¡Œè®­ç»ƒå‘½ä»¤:"
    echo "$TRAIN_CMD"
    echo ""
    
    # å¼€å§‹è®­ç»ƒè®¡æ—¶
    TRAIN_START_TIME=$(date +%s)
    
    # æ‰§è¡Œè®­ç»ƒ
    if eval "$TRAIN_CMD"; then
        TRAIN_END_TIME=$(date +%s)
        TRAIN_DURATION=$((TRAIN_END_TIME - TRAIN_START_TIME))
        TRAIN_HOURS=$((TRAIN_DURATION / 3600))
        TRAIN_MINUTES=$(((TRAIN_DURATION % 3600) / 60))
        
        log_success "è®­ç»ƒå®Œæˆ!"
        log_success "è®­ç»ƒç”¨æ—¶: ${TRAIN_HOURS}å°æ—¶${TRAIN_MINUTES}åˆ†é’Ÿ"
    else
        log_error "è®­ç»ƒå¤±è´¥!"
        exit 1
    fi
}

# è‡ªåŠ¨è¯„ä¼°æ¨¡å‹
evaluate_model() {
    log_info "å¼€å§‹æ¨¡å‹è¯„ä¼°..."
    
    # è¯„ä¼°å‘½ä»¤
    EVAL_CMD="python scripts/evaluate.py \
        --data_dir data/raw \
        --model_path data/models/best_model.pth \
        --output_dir evaluation_results"
    
    if eval "$EVAL_CMD"; then
        log_success "æ¨¡å‹è¯„ä¼°å®Œæˆ!"
        log_success "è¯„ä¼°ç»“æœä¿å­˜åœ¨: evaluation_results/"
        
        # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
        if [[ -f "evaluation_results/evaluation_report_*.json" ]]; then
            python3 -c "
import json
import glob
latest_file = max(glob.glob('evaluation_results/evaluation_report_*.json'))
with open(latest_file) as f:
    report = json.load(f)

if 'performance_evaluation' in report:
    perf = report['performance_evaluation']['basic_metrics']
    print(f'ğŸ“Š æ¨¡å‹æ€§èƒ½æŒ‡æ ‡:')
    print(f'   å‡†ç¡®ç‡: {perf[\"accuracy\"]:.3f}')
    print(f'   F1åˆ†æ•°: {perf[\"macro_f1\"]:.3f}')
    print(f'   ç²¾ç¡®ç‡: {perf[\"macro_precision\"]:.3f}')
    print(f'   å¬å›ç‡: {perf[\"macro_recall\"]:.3f}')
"
        fi
    else
        log_warning "æ¨¡å‹è¯„ä¼°å¤±è´¥ï¼Œä½†è®­ç»ƒå®Œæˆ"
    fi
}

# å¯åŠ¨APIæœåŠ¡
start_api_service() {
    log_info "å¯åŠ¨APIæœåŠ¡..."
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if [[ -f "data/models/best_model.pth" ]]; then
        log_success "æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¯åŠ¨APIæœåŠ¡..."
        
        # å¯åŠ¨APIï¼ˆåå°è¿è¡Œï¼‰
        nohup python main.py > api_service.log 2>&1 &
        API_PID=$!
        
        log_success "APIæœåŠ¡å·²å¯åŠ¨ (PID: $API_PID)"
        log_info "APIåœ°å€: http://localhost:8000"
        log_info "APIæ–‡æ¡£: http://localhost:8000/docs"
        log_info "æœåŠ¡æ—¥å¿—: api_service.log"
        
        # ä¿å­˜PIDåˆ°æ–‡ä»¶
        echo $API_PID > api_service.pid
        log_success "API PIDå·²ä¿å­˜: api_service.pid"
        
        # ç­‰å¾…æœåŠ¡å¯åŠ¨
        sleep 5
        
        # æµ‹è¯•API
        if curl -s http://localhost:8000/health > /dev/null; then
            log_success "APIæœåŠ¡æµ‹è¯•é€šè¿‡!"
        else
            log_warning "APIæœåŠ¡å¯èƒ½è¿˜åœ¨å¯åŠ¨ä¸­ï¼Œè¯·ç¨åæµ‹è¯•"
        fi
        
    else
        log_warning "æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè·³è¿‡APIå¯åŠ¨"
    fi
}

# ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
generate_report() {
    log_info "ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š..."
    
    REPORT_FILE="training_report_$(date +%Y%m%d_%H%M%S).md"
    
    cat > "$REPORT_FILE" << EOF
# ç»„ç»‡ç—…ç†CNNè®­ç»ƒæŠ¥å‘Š

## è®­ç»ƒé…ç½®
- æ¨¡å‹ç±»å‹: $MODEL_TYPE
- æ‰¹æ¬¡å¤§å°: $BATCH_SIZE
- å›¾åƒå°ºå¯¸: $IMG_SIZE
- è®­ç»ƒè½®æ¬¡: $EPOCHS
- GPUåŠ é€Ÿ: $USE_GPU
- è®­ç»ƒæ—¶é—´: $(date)

## æ•°æ®ç»Ÿè®¡
EOF
    
    if [[ -f "training_config.json" ]]; then
        python3 -c "
import json
import os
from pathlib import Path

# ç»Ÿè®¡æ•°æ®
data_dir = Path('data/raw')
total_images = 0
class_stats = {}

if data_dir.exists():
    for class_dir in data_dir.iterdir():
        if class_dir.is_dir():
            images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.png')) + list(class_dir.glob('*.tiff'))
            class_stats[class_dir.name] = len(images)
            total_images += len(images)

print('### æ•°æ®åˆ†å¸ƒ')
print(f'- æ€»å›¾åƒæ•°: {total_images}')
print(f'- ç±»åˆ«æ•°: {len(class_stats)}')
print('')
print('#### å„ç±»åˆ«æ•°é‡')
for class_name, count in sorted(class_stats.items()):
    print(f'- {class_name}: {count} å¼ ')
" >> "$REPORT_FILE"
    fi
    
    echo "" >> "$REPORT_FILE"
    echo "## æ¨¡å‹æ–‡ä»¶" >> "$REPORT_FILE"
    echo "- æœ€ä½³æ¨¡å‹: \`data/models/best_model.pth\`" >> "$REPORT_FILE"
    echo "- æœ€æ–°æ¨¡å‹: \`data/models/latest_model.pth\`" >> "$REPORT_FILE"
    echo "- è®­ç»ƒå†å²: \`data/models/training_history/\`" >> "$REPORT_FILE"
    
    echo "" >> "$REPORT_FILE"
    echo "## APIæœåŠ¡" >> "$REPORT_FILE"
    echo "- APIåœ°å€: http://localhost:8000" >> "$REPORT_FILE"
    echo "- APIæ–‡æ¡£: http://localhost:8000/docs" >> "$REPORT_FILE"
    echo "- å¥åº·æ£€æŸ¥: http://localhost:8000/health" >> "$REPORT_FILE"
    
    log_success "è®­ç»ƒæŠ¥å‘Šå·²ç”Ÿæˆ: $REPORT_FILE"
}

# ä¸»å‡½æ•°
main() {
    echo "ğŸ¤– ç»„ç»‡ç—…ç†CNNå…¨è‡ªåŠ¨è®­ç»ƒç³»ç»Ÿ"
    echo "=================================="
    echo ""
    
    # æ£€æŸ¥æ˜¯å¦åœ¨æ­£ç¡®çš„ç›®å½•
    if [[ ! -f "main.py" ]] || [[ ! -f "requirements.txt" ]]; then
        log_error "è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬"
        exit 1
    fi
    
    # æ‰§è¡Œè®­ç»ƒæµç¨‹
    check_environment
    install_dependencies
    prepare_directories
    check_training_data
    select_optimal_config
    
    echo ""
    log_info "ğŸš€ å¼€å§‹å…¨è‡ªåŠ¨è®­ç»ƒæµç¨‹"
    echo ""
    
    start_training
    evaluate_model
    start_api_service
    generate_report
    
    echo ""
    log_success "ğŸ‰ å…¨è‡ªåŠ¨è®­ç»ƒå®Œæˆ!"
    echo ""
    log_info "ğŸ“Š è®­ç»ƒç»“æœ:"
    echo "   âœ… æ¨¡å‹è®­ç»ƒ: data/models/best_model.pth"
    echo "   âœ… æ¨¡å‹è¯„ä¼°: evaluation_results/"
    echo "   âœ… APIæœåŠ¡: http://localhost:8000"
    echo "   âœ… è®­ç»ƒæŠ¥å‘Š: training_report_*.md"
    echo ""
    log_info "ğŸš€ æ‚¨å¯ä»¥:"
    echo "   1. è®¿é—®APIæ–‡æ¡£: http://localhost:8000/docs"
    echo "   2. æµ‹è¯•é¢„æµ‹: curl -X POST http://localhost:8000/predict -F 'file=@test_image.jpg'"
    echo "   3. åœæ­¢API: kill \$(cat api_service.pid)"
    echo ""
}

# é”™è¯¯å¤„ç†
trap 'log_error "è®­ç»ƒè¿‡ç¨‹ä¸­æ–­"; exit 1' INT TERM

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"