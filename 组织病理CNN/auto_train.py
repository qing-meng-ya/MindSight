#!/usr/bin/env python3
"""
ç»„ç»‡ç—…ç†CNNå…¨è‡ªåŠ¨è®­ç»ƒç³»ç»Ÿ

åªéœ€å‡†å¤‡æ•°æ®ï¼Œå…¶ä»–å…¨éƒ¨è‡ªåŠ¨åŒ–
"""

import os
import sys
import json
import time
import subprocess
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

try:
    import torch
    import cv2
    import fastapi
    from src.data import PathologyDataLoader
    from src.models import ModelFactory
    from src.training import Trainer
    from configs.config import Config
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·å…ˆå®‰è£…ä¾èµ–: pip install -r requirements.txt")
    sys.exit(1)

class AutoTrainingSystem:
    """å…¨è‡ªåŠ¨è®­ç»ƒç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–è®­ç»ƒç³»ç»Ÿ"""
        self.setup_logging()
        self.logger = logging.getLogger(__name__)
        
        # è®­ç»ƒé…ç½®
        self.config = {}
        self.training_stats = {}
        
        # ç³»ç»Ÿä¿¡æ¯
        self.system_info = self.get_system_info()
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = log_dir / f"auto_training_{timestamp}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("ğŸ¤– ç»„ç»‡ç—…ç†CNNå…¨è‡ªåŠ¨è®­ç»ƒç³»ç»Ÿå¯åŠ¨")
    
    def get_system_info(self) -> Dict:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        info = {
            "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
            "pytorch_version": torch.__version__,
            "cuda_available": torch.cuda.is_available(),
            "opencv_version": cv2.__version__,
            "fastapi_version": fastapi.__version__
        }
        
        if torch.cuda.is_available():
            info["gpu_name"] = torch.cuda.get_device_name(0)
            info["gpu_memory"] = torch.cuda.get_device_properties(0).total_memory / 1024**3
            info["gpu_count"] = torch.cuda.device_count()
        
        return info
    
    def check_environment(self) -> bool:
        """æ£€æŸ¥ç¯å¢ƒ"""
        self.logger.info("ğŸ” æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ...")
        
        # æ£€æŸ¥Pythonç‰ˆæœ¬
        if sys.version_info < (3, 8):
            self.logger.error("âŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦3.8+")
            return False
        
        # æ£€æŸ¥å…³é”®åŒ…
        required_packages = ['torch', 'cv2', 'fastapi', 'numpy', 'PIL']
        for package in required_packages:
            try:
                __import__(package)
            except ImportError:
                self.logger.error(f"âŒ ç¼ºå°‘åŒ…: {package}")
                return False
        
        # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
        self.logger.info("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
        self.logger.info(f"   Python: {self.system_info['python_version']}")
        self.logger.info(f"   PyTorch: {self.system_info['pytorch_version']}")
        self.logger.info(f"   CUDA: {'å¯ç”¨' if self.system_info['cuda_available'] else 'ä¸å¯ç”¨'}")
        
        if self.system_info['cuda_available']:
            self.logger.info(f"   GPU: {self.system_info['gpu_name']}")
            self.logger.info(f"   GPUå†…å­˜: {self.system_info['gpu_memory']:.1f}GB")
        
        return True
    
    def prepare_directories(self) -> bool:
        """å‡†å¤‡ç›®å½•ç»“æ„"""
        self.logger.info("ğŸ“ å‡†å¤‡ç›®å½•ç»“æ„...")
        
        required_dirs = [
            "data/raw",
            "data/processed", 
            "data/models",
            "evaluation_results",
            "logs"
        ]
        
        for dir_path in required_dirs:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
        
        self.logger.info("âœ… ç›®å½•ç»“æ„å‡†å¤‡å®Œæˆ")
        return True
    
    def check_training_data(self) -> Dict:
        """æ£€æŸ¥è®­ç»ƒæ•°æ®"""
        self.logger.info("ğŸ“Š æ£€æŸ¥è®­ç»ƒæ•°æ®...")
        
        data_dir = Path("data/raw")
        
        if not data_dir.exists():
            self.logger.error("âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: data/raw")
            self.logger.error("è¯·æŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡æ•°æ®:")
            self.logger.error("data/raw/")
            self.logger.error("â”œâ”€â”€ è‚ºç‚/")
            self.logger.error("â”‚   â”œâ”€â”€ image001.jpg")
            self.logger.error("â”‚   â””â”€â”€ image002.jpg")
            self.logger.error("â”œâ”€â”€ è‚ºå‡ºè¡€/")
            self.logger.error("â””â”€â”€ ...")
            return {"valid": False}
        
        # ç»Ÿè®¡æ•°æ®
        total_images = 0
        class_stats = {}
        valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}
        
        for class_dir in data_dir.iterdir():
            if class_dir.is_dir():
                class_name = class_dir.name
                images = []
                
                for ext in valid_extensions:
                    images.extend(class_dir.glob(f"*{ext}"))
                    images.extend(class_dir.glob(f"*{ext.upper()}"))
                
                if images:
                    class_stats[class_name] = len(images)
                    total_images += len(images)
        
        if total_images == 0:
            self.logger.error("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å›¾åƒæ–‡ä»¶")
            return {"valid": False}
        
        # æ•°æ®è´¨é‡è¯„ä¼°
        data_quality = self.assess_data_quality(class_stats, total_images)
        
        self.logger.info("âœ… æ•°æ®æ£€æŸ¥å®Œæˆ")
        self.logger.info(f"   æ€»å›¾åƒæ•°: {total_images}")
        self.logger.info(f"   ç±»åˆ«æ•°: {len(class_stats)}")
        
        for class_name, count in sorted(class_stats.items()):
            self.logger.info(f"   {class_name}: {count} å¼ å›¾åƒ")
        
        return {
            "valid": True,
            "total_images": total_images,
            "class_count": len(class_stats),
            "class_stats": class_stats,
            "quality": data_quality
        }
    
    def assess_data_quality(self, class_stats: Dict, total_images: int) -> Dict:
        """è¯„ä¼°æ•°æ®è´¨é‡"""
        quality = {"score": 0, "issues": [], "recommendations": []}
        
        # æ•°æ®é‡è¯„ä¼°
        if total_images >= 1000:
            quality["score"] += 30
        elif total_images >= 500:
            quality["score"] += 20
        elif total_images >= 100:
            quality["score"] += 10
        else:
            quality["issues"].append("æ•°æ®é‡è¿‡å°‘ï¼Œå¯èƒ½å½±å“è®­ç»ƒæ•ˆæœ")
            quality["recommendations"].append("å»ºè®®æ¯ç±»è‡³å°‘50å¼ å›¾åƒ")
        
        # ç±»åˆ«å¹³è¡¡æ€§è¯„ä¼°
        if class_stats:
            counts = list(class_stats.values())
            max_count = max(counts)
            min_count = min(counts)
            balance_ratio = max_count / min_count if min_count > 0 else float('inf')
            
            if balance_ratio <= 2:
                quality["score"] += 30
            elif balance_ratio <= 5:
                quality["score"] += 20
            else:
                quality["issues"].append("æ•°æ®åˆ†å¸ƒä¸å¹³è¡¡")
                quality["recommendations"].append("è€ƒè™‘ä½¿ç”¨ç±»åˆ«æƒé‡æˆ–æ•°æ®å¢å¼º")
        
        # æ¯ç±»æœ€å°æ ·æœ¬æ•°
        min_samples = min(class_stats.values()) if class_stats else 0
        if min_samples >= 50:
            quality["score"] += 20
        elif min_samples >= 20:
            quality["score"] += 10
        else:
            quality["issues"].append("éƒ¨åˆ†ç±»åˆ«æ ·æœ¬è¿‡å°‘")
            quality["recommendations"].append("å»ºè®®æ¯ç±»è‡³å°‘20å¼ å›¾åƒ")
        
        # ç±»åˆ«æ•°é‡
        class_count = len(class_stats)
        if class_count == len(Config.PATHOLOGY_CLASSES):
            quality["score"] += 20
        elif class_count >= 10:
            quality["score"] += 15
        elif class_count >= 5:
            quality["score"] += 10
        else:
            quality["issues"].append("ç±»åˆ«æ•°é‡è¿‡å°‘")
            quality["recommendations"].append("å»ºè®®å¢åŠ æ›´å¤šç—…ç†ç±»å‹")
        
        return quality
    
    def select_optimal_config(self, data_info: Dict) -> Dict:
        """è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜é…ç½®"""
        self.logger.info("ğŸ¯ è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è®­ç»ƒé…ç½®...")
        
        # åŸºç¡€é…ç½®
        config = {
            "model_type": "resnet50",
            "batch_size": 16,
            "img_size": 224,
            "epochs": 50,
            "learning_rate": 0.001,
            "loss_type": "focal",
            "use_class_weights": True,
            "device": "cuda" if self.system_info['cuda_available'] else "cpu"
        }
        
        # æ ¹æ®GPUè°ƒæ•´é…ç½®
        if self.system_info['cuda_available']:
            gpu_memory = self.system_info['gpu_memory']
            
            if gpu_memory >= 24:  # RTX 4090/3090/A100
                config.update({
                    "model_type": "efficientnet_b1",
                    "batch_size": 32,
                    "img_size": 384,
                    "epochs": 100
                })
            elif gpu_memory >= 16:  # RTX 3080/4080
                config.update({
                    "batch_size": 24,
                    "img_size": 320,
                    "epochs": 80
                })
            elif gpu_memory >= 12:  # RTX 3060/3070
                config.update({
                    "batch_size": 16,
                    "img_size": 256,
                    "epochs": 60
                })
        
        # æ ¹æ®æ•°æ®é‡è°ƒæ•´
        total_images = data_info.get("total_images", 0)
        if total_images < 200:
            config["epochs"] = min(config["epochs"], 30)
        elif total_images > 1000:
            config["epochs"] = min(config["epochs"], 150)
        
        # æ ¹æ®æ•°æ®è´¨é‡è°ƒæ•´
        quality = data_info.get("quality", {})
        if quality.get("issues"):
            config["use_class_weights"] = True
            config["loss_type"] = "focal"
        
        self.config = config
        
        # æ˜¾ç¤ºé…ç½®
        self.logger.info("âœ… è®­ç»ƒé…ç½®:")
        for key, value in config.items():
            self.logger.info(f"   {key}: {value}")
        
        # ä¿å­˜é…ç½®
        config_file = "auto_training_config.json"
        with open(config_file, 'w') as f:
            json.dump(config, f, indent=2)
        
        self.logger.info(f"âœ… é…ç½®å·²ä¿å­˜: {config_file}")
        return config
    
    def start_training(self, config: Dict) -> bool:
        """å¼€å§‹è®­ç»ƒ"""
        self.logger.info("ğŸš€ å¼€å§‹è‡ªåŠ¨è®­ç»ƒ...")
        
        try:
            # åˆ›å»ºæ•°æ®åŠ è½½å™¨
            self.logger.info("ğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
            data_loader = PathologyDataLoader(
                data_dir="data/raw",
                batch_size=config["batch_size"],
                img_size=config["img_size"],
                num_workers=4
            )
            
            train_loader = data_loader.get_train_loader()
            val_loader = data_loader.get_val_loader()
            test_loader = data_loader.get_test_loader()
            
            self.logger.info(f"   è®­ç»ƒæ ·æœ¬: {len(train_loader.dataset)}")
            self.logger.info(f"   éªŒè¯æ ·æœ¬: {len(val_loader.dataset)}")
            self.logger.info(f"   æµ‹è¯•æ ·æœ¬: {len(test_loader.dataset)}")
            
            # åˆ›å»ºæ¨¡å‹
            self.logger.info("ğŸ—ï¸ åˆ›å»ºæ¨¡å‹...")
            model = ModelFactory.create_model(
                model_type=config["model_type"],
                num_classes=len(Config.PATHOLOGY_CLASSES),
                pretrained=True
            )
            
            model = model.to(config["device"])
            param_count = sum(p.numel() for p in model.parameters())
            self.logger.info(f"   æ¨¡å‹å‚æ•°: {param_count:,}")
            
            # åˆ›å»ºè®­ç»ƒå™¨
            self.logger.info("ğŸ‹ï¸ åˆ›å»ºè®­ç»ƒå™¨...")
            trainer = Trainer(
                model=model,
                train_loader=train_loader,
                val_loader=val_loader,
                test_loader=test_loader,
                model_config=config,
                device=config["device"]
            )
            
            # è®¾ç½®è®­ç»ƒ
            trainer.setup_training(
                learning_rate=config["learning_rate"],
                use_focal_loss=(config["loss_type"] == "focal")
            )
            
            # å¼€å§‹è®­ç»ƒ
            self.logger.info("ğŸ¯ å¼€å§‹è®­ç»ƒæµç¨‹...")
            start_time = time.time()
            
            history = trainer.train(
                num_epochs=config["epochs"],
                early_stopping_patience=15,
                save_every=10
            )
            
            training_time = time.time() - start_time
            self.training_stats["training_time"] = training_time
            self.training_stats["history"] = history
            
            self.logger.info(f"âœ… è®­ç»ƒå®Œæˆ! ç”¨æ—¶: {training_time/3600:.2f}å°æ—¶")
            
            # æµ‹è¯•æ¨¡å‹
            self.logger.info("ğŸ§ª æµ‹è¯•æ¨¡å‹...")
            test_metrics = trainer.test()
            self.training_stats["test_metrics"] = test_metrics
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
            return False
    
    def evaluate_model(self) -> bool:
        """è¯„ä¼°æ¨¡å‹"""
        self.logger.info("ğŸ“Š å¼€å§‹æ¨¡å‹è¯„ä¼°...")
        
        try:
            # è¿è¡Œè¯„ä¼°è„šæœ¬
            eval_cmd = [
                "python", "scripts/evaluate.py",
                "--data_dir", "data/raw",
                "--model_path", "data/models/best_model.pth",
                "--output_dir", "evaluation_results"
            ]
            
            result = subprocess.run(eval_cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                self.logger.info("âœ… æ¨¡å‹è¯„ä¼°å®Œæˆ")
                self.logger.info("ğŸ“ è¯„ä¼°ç»“æœ: evaluation_results/")
                return True
            else:
                self.logger.error(f"âŒ è¯„ä¼°å¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ è¯„ä¼°é”™è¯¯: {e}")
            return False
    
    def start_api_service(self) -> bool:
        """å¯åŠ¨APIæœåŠ¡"""
        self.logger.info("ğŸŒ å¯åŠ¨APIæœåŠ¡...")
        
        try:
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
            model_file = Path("data/models/best_model.pth")
            if not model_file.exists():
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè·³è¿‡APIå¯åŠ¨")
                return False
            
            # å¯åŠ¨APIæœåŠ¡ï¼ˆåå°ï¼‰
            import subprocess
            import signal
            
            api_cmd = ["python", "main.py"]
            process = subprocess.Popen(
                api_cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            # ç­‰å¾…æœåŠ¡å¯åŠ¨
            time.sleep(5)
            
            # æµ‹è¯•API
            try:
                import requests
                response = requests.get("http://localhost:8000/health", timeout=5)
                if response.status_code == 200:
                    self.logger.info("âœ… APIæœåŠ¡å¯åŠ¨æˆåŠŸ")
                    self.logger.info("ğŸŒ APIåœ°å€: http://localhost:8000")
                    self.logger.info("ğŸ“š APIæ–‡æ¡£: http://localhost:8000/docs")
                    
                    # ä¿å­˜è¿›ç¨‹ä¿¡æ¯
                    self.training_stats["api_pid"] = process.pid
                    with open("api_service.pid", 'w') as f:
                        f.write(str(process.pid))
                    
                    return True
                else:
                    self.logger.warning("âš ï¸ APIæœåŠ¡å¯èƒ½è¿˜åœ¨å¯åŠ¨ä¸­")
                    return False
            except:
                self.logger.warning("âš ï¸ APIæœåŠ¡æµ‹è¯•å¤±è´¥")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ APIå¯åŠ¨å¤±è´¥: {e}")
            return False
    
    def generate_report(self) -> str:
        """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
        self.logger.info("ğŸ“‹ ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"auto_training_report_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# ç»„ç»‡ç—…ç†CNNè‡ªåŠ¨è®­ç»ƒæŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # ç³»ç»Ÿä¿¡æ¯
            f.write("## ç³»ç»Ÿç¯å¢ƒ\n\n")
            f.write(f"- Pythonç‰ˆæœ¬: {self.system_info['python_version']}\n")
            f.write(f"- PyTorchç‰ˆæœ¬: {self.system_info['pytorch_version']}\n")
            f.write(f"- CUDAå¯ç”¨: {self.system_info['cuda_available']}\n")
            
            if self.system_info['cuda_available']:
                f.write(f"- GPU: {self.system_info['gpu_name']}\n")
                f.write(f"- GPUå†…å­˜: {self.system_info['gpu_memory']:.1f}GB\n")
            
            # è®­ç»ƒé…ç½®
            f.write("\n## è®­ç»ƒé…ç½®\n\n")
            for key, value in self.config.items():
                f.write(f"- {key}: {value}\n")
            
            # è®­ç»ƒç»“æœ
            if self.training_stats:
                f.write("\n## è®­ç»ƒç»“æœ\n\n")
                
                if "training_time" in self.training_stats:
                    training_time = self.training_stats["training_time"]
                    f.write(f"- è®­ç»ƒç”¨æ—¶: {training_time/3600:.2f}å°æ—¶\n")
                
                if "test_metrics" in self.training_stats:
                    metrics = self.training_stats["test_metrics"]
                    f.write(f"- æµ‹è¯•å‡†ç¡®ç‡: {metrics.get('accuracy', 0):.3f}\n")
                    f.write(f"- æµ‹è¯•F1åˆ†æ•°: {metrics.get('macro_f1', 0):.3f}\n")
            
            # æ–‡ä»¶ä½ç½®
            f.write("\n## ç”Ÿæˆæ–‡ä»¶\n\n")
            f.write("- æœ€ä½³æ¨¡å‹: `data/models/best_model.pth`\n")
            f.write("- æœ€æ–°æ¨¡å‹: `data/models/latest_model.pth`\n")
            f.write("- è¯„ä¼°ç»“æœ: `evaluation_results/`\n")
            f.write("- è®­ç»ƒæ—¥å¿—: `logs/`\n")
            
            # APIæœåŠ¡
            f.write("\n## APIæœåŠ¡\n\n")
            f.write("- APIåœ°å€: http://localhost:8000\n")
            f.write("- APIæ–‡æ¡£: http://localhost:8000/docs\n")
            f.write("- å¥åº·æ£€æŸ¥: http://localhost:8000/health\n")
            
            # ä½¿ç”¨è¯´æ˜
            f.write("\n## ä½¿ç”¨è¯´æ˜\n\n")
            f.write("### æµ‹è¯•é¢„æµ‹\n")
            f.write("```bash\n")
            f.write("curl -X POST http://localhost:8000/predict \\\n")
            f.write("  -F 'file=@test_image.jpg'\n")
            f.write("```\n\n")
            
            f.write("### åœæ­¢APIæœåŠ¡\n")
            f.write("```bash\n")
            f.write("kill $(cat api_service.pid)\n")
            f.write("```\n")
        
        self.logger.info(f"âœ… è®­ç»ƒæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        return report_file
    
    def run_full_pipeline(self) -> bool:
        """è¿è¡Œå®Œæ•´è®­ç»ƒæµç¨‹"""
        try:
            # 1. ç¯å¢ƒæ£€æŸ¥
            if not self.check_environment():
                return False
            
            # 2. å‡†å¤‡ç›®å½•
            if not self.prepare_directories():
                return False
            
            # 3. æ£€æŸ¥æ•°æ®
            data_info = self.check_training_data()
            if not data_info["valid"]:
                return False
            
            # 4. é€‰æ‹©é…ç½®
            config = self.select_optimal_config(data_info)
            
            # 5. å¼€å§‹è®­ç»ƒ
            if not self.start_training(config):
                return False
            
            # 6. è¯„ä¼°æ¨¡å‹
            self.evaluate_model()
            
            # 7. å¯åŠ¨API
            self.start_api_service()
            
            # 8. ç”ŸæˆæŠ¥å‘Š
            report_file = self.generate_report()
            
            # 9. æ˜¾ç¤ºç»“æœ
            self.show_final_results(report_file)
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ è®­ç»ƒæµç¨‹å¤±è´¥: {e}")
            return False
    
    def show_final_results(self, report_file: str):
        """æ˜¾ç¤ºæœ€ç»ˆç»“æœ"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ‰ å…¨è‡ªåŠ¨è®­ç»ƒå®Œæˆ!")
        self.logger.info("="*60)
        
        self.logger.info("\nğŸ“Š è®­ç»ƒç»“æœ:")
        self.logger.info("   âœ… æ¨¡å‹è®­ç»ƒ: data/models/best_model.pth")
        self.logger.info("   âœ… æ¨¡å‹è¯„ä¼°: evaluation_results/")
        self.logger.info("   âœ… APIæœåŠ¡: http://localhost:8000")
        self.logger.info("   âœ… è®­ç»ƒæŠ¥å‘Š: " + report_file)
        
        if self.training_stats:
            if "training_time" in self.training_stats:
                time_hours = self.training_stats["training_time"] / 3600
                self.logger.info(f"   â±ï¸ è®­ç»ƒç”¨æ—¶: {time_hours:.2f}å°æ—¶")
            
            if "test_metrics" in self.training_stats:
                metrics = self.training_stats["test_metrics"]
                self.logger.info(f"   ğŸ“ˆ æµ‹è¯•å‡†ç¡®ç‡: {metrics.get('accuracy', 0):.3f}")
                self.logger.info(f"   ğŸ“ˆ æµ‹è¯•F1åˆ†æ•°: {metrics.get('macro_f1', 0):.3f}")
        
        self.logger.info("\nğŸš€ æ‚¨å¯ä»¥:")
        self.logger.info("   1. è®¿é—®APIæ–‡æ¡£: http://localhost:8000/docs")
        self.logger.info("   2. æµ‹è¯•é¢„æµ‹: curl -X POST http://localhost:8000/predict -F 'file=@test_image.jpg'")
        self.logger.info("   3. æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: " + report_file)
        
        if "api_pid" in self.training_stats:
            self.logger.info("   4. åœæ­¢API: kill $(cat api_service.pid)")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– ç»„ç»‡ç—…ç†CNNå…¨è‡ªåŠ¨è®­ç»ƒç³»ç»Ÿ")
    print("=" * 50)
    
    # æ£€æŸ¥æ˜¯å¦åœ¨æ­£ç¡®ç›®å½•
    if not Path("main.py").exists() or not Path("requirements.txt").exists():
        print("âŒ è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
        return 1
    
    # åˆ›å»ºè®­ç»ƒç³»ç»Ÿ
    trainer = AutoTrainingSystem()
    
    # è¿è¡Œå®Œæ•´æµç¨‹
    success = trainer.run_full_pipeline()
    
    return 0 if success else 1

if __name__ == "__main__":
    sys.exit(main())